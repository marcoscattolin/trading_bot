#  Copyright (c) 2024, Boston Consulting Group.
#  Authors: Marco Scattolin
#  License: Proprietary

# Builder step used to download and configure spark environment
FROM ubuntu:22.04

USER root

ARG PYTHON_VERSION
ARG DEBIAN_FRONTEND=noninteractive
ARG TZ=Etc/UTC
ENV LC_ALL=C.UTF-8
ENV PATH=$PATH:/root/.local/bin

# +++ SPARK +++
ARG SPARK_VERSION
ARG HADOOP_VERSION
ENV SPARK_HOME=/opt/spark
ENV PYTHONHASHSEED=1
# --- SPARK ---

# update
RUN apt-get update

# libraries
RUN apt-get install -y  \
    wget  \
    python${PYTHON_VERSION}  \
    python${PYTHON_VERSION}-distutils

# +++ SPARK +++
# install java
RUN apt-get install -y default-jre
# --- SPARK ---


# set default python3
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1

# Install pip
RUN wget "https://bootstrap.pypa.io/get-pip.py" -O get-pip.py --no-check-certificate
RUN python3 get-pip.py

# Copy project files
COPY pyproject.toml /opt
COPY README.md /opt
COPY src /opt/src

# Install .toml dependencies
RUN pip install --upgrade pip poetry
RUN poetry config virtualenvs.create false
RUN cd /opt && poetry install --with spark

# +++ SPARK +++
# Download and uncompress spark from the apache archive
RUN wget -O apache-spark.tgz "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" \
&& mkdir -p ${SPARK_HOME} \
&& tar -xf apache-spark.tgz -C ${SPARK_HOME} --strip-components=1 \
&& rm apache-spark.tgz

# copy spark jars for interacting with S3 and database
COPY docker/drivers/postgresql-42.5.4.jar ${SPARK_HOME}/jars/postgresql-42.5.4.jar
COPY docker/drivers/hadoop-common-3.3.4.jar ${SPARK_HOME}/jars/hadoop-common-3.3.4.jar
COPY docker/drivers/hadoop-common-3.3.4.jar ${SPARK_HOME}/jars/hadoop-common-3.3.4.jar
COPY docker/drivers/hadoop-aws-3.3.4.jar ${SPARK_HOME}/jars/hadoop-aws-3.3.4.jar
RUN wget -O ${SPARK_HOME}/jars/aws-java-sdk-bundle-1.12.594.jar "https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.594/aws-java-sdk-bundle-1.12.594.jar"
# --- SPARK ---

# setup jupyter notebook
RUN /usr/local/bin/jupyter-notebook --generate-config \
    && echo "c.NotebookApp.allow_root=True" >> /root/.jupyter/jupyter_notebook_config.py \
    && echo "c.NotebookApp.ip='0.0.0.0'" >> /root/.jupyter/jupyter_notebook_config.py


WORKDIR /opt
